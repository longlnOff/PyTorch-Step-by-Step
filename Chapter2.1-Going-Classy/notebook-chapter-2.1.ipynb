{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spoilers\n",
    "\n",
    "- Define a class to handle model training.\n",
    "- Implement the constructor method,\n",
    "- Understanding the differnce between public, protected and private methods of a class.\n",
    "- Integrate the code we've deveploed so far into the class.\n",
    "- Instantiate our class and use it to run a classy pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 22:24:51.728927: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-07 22:24:53.033876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Classy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A completely empty class\n",
    "class StepByStep(object):\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Constructor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"From where do we start building a class?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That would be the constructor, the \\__init__(self) method that define the parts that make up class. These parts are the attributes of the class. Typical attributes include:\n",
    "- **arguments** provided by user.\n",
    "- **placeholders** for other objects that are not available at the moment of creation.\n",
    "- **variables** we may want to keep track of.\n",
    "- **function** that are dynamically built using some of the arguments and higher-order functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three arguments of constructor is:\n",
    "- model\n",
    "- loss_fn\n",
    "- optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        # We start by storing the arguments as attributes\n",
    "        # to use later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead\")\n",
    "            self.model.to(self.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders or delayed arguments - we expect the user to eventually provide some of these, as they are not necessarily required."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders includes:\n",
    "- train dataloaders\n",
    "- validation dataloaders\n",
    "- summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        # We start by storing the arguments as attributes to use them later\n",
    "        # arguments\n",
    "        self.model      = model\n",
    "        self.loss_fn    = loss_fn\n",
    "        self.optimizer  = optimizer\n",
    "        self.device     = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # placeholders for later\n",
    "        self.train_loader   = None\n",
    "        self.val_loader     = None\n",
    "        self.writer         = None\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which data loaders to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader   = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to specify a name for SummaryWriter\n",
    "        # to interface with TensorBoard\n",
    "        suffix = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are the quantity that we may want to keep track of, including:\n",
    "- number of epochs\n",
    "- losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        # We start by storing the arguments as attributes to use them later\n",
    "        # arguments\n",
    "        self.model      = model\n",
    "        self.loss_fn    = loss_fn\n",
    "        self.optimizer  = optimizer\n",
    "        self.device     = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # placeholders for later\n",
    "        self.train_loader   = None\n",
    "        self.val_loader     = None\n",
    "        self.writer         = None\n",
    "\n",
    "        # variables\n",
    "        self.train_losses   = []\n",
    "        self.val_losses     = []\n",
    "        self.total_epochs   = 0\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which data loaders to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader   = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to specify a name for SummaryWriter\n",
    "        # to interface with TensorBoard\n",
    "        suffix = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        # We start by storing the arguments as attributes to use them later\n",
    "        # arguments\n",
    "        self.model      = model\n",
    "        self.loss_fn    = loss_fn\n",
    "        self.optimizer  = optimizer\n",
    "        self.device     = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # placeholders for later\n",
    "        self.train_loader   = None\n",
    "        self.val_loader     = None\n",
    "        self.writer         = None\n",
    "\n",
    "        # variables\n",
    "        self.train_losses   = []\n",
    "        self.val_losses     = []\n",
    "        self.total_epochs   = 0\n",
    "\n",
    "        # Creates the train_step function for our model, loss function and optimizer\n",
    "        self.train_step_fn  = self._make_train_step_fn()\n",
    "        # Creates the val_step function for our model and loss function\n",
    "        self.val_step_fn    = self._make_val_step_fn()\n",
    "\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which data loaders to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader   = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to specify a name for SummaryWriter\n",
    "        # to interface with TensorBoard\n",
    "        suffix = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')\n",
    "\n",
    "    def _make_train_step_fn(self):\n",
    "        # Builds function that performs a step in the train loop\n",
    "        def perform_train_step_fn(x, y):\n",
    "            # Set model to TRAIN mode\n",
    "            self.model.train()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "\n",
    "            # Step 3 - Computes gradients for both model's parameters and loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Step 4 - Updates parameters using gradients and the chosen optimizer\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Returns the loss\n",
    "            return loss.item()\n",
    "        \n",
    "        # Returns the function that will be called inside the train loop\n",
    "        return perform_train_step_fn\n",
    "    \n",
    "    def _make_val_step_fn(self):\n",
    "        # Builds function that performs a step in the validation loop\n",
    "        def perform_val_step_fn(x, y):\n",
    "            # Set model to EVAL mode\n",
    "            self.model.eval()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "\n",
    "            # Returns the loss and the predictions\n",
    "            return loss.item()\n",
    "        \n",
    "        # Returns the function that will be called inside the val loop\n",
    "        return perform_val_step_fn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**public methods (methods), protected methods (_methods), private methods (__methods)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In others programming languages like Java have three kinds of methods: public, protected and private.\n",
    "- Public methods can be called from anywhere.\n",
    "- Protected methods can be called from the class itself and its subclasses.\n",
    "- Private methods can only be called from the class itself.\n",
    "\n",
    "But in Python, there is no way to enforce this. The convention is to use a single underscore prefix for protected methods and a double underscore prefix for private methods. This is just a convention, though, and Python won't stop you from calling these methods from outside the class. But you shouldn't do that, unless you know what you're doing.\n",
    "\n",
    "Convention:\n",
    "- public methods: no underscore -                  (methodname)\n",
    "- protected methods: single underscore prefix -    (_methodname)\n",
    "- private methods: double underscore prefix -      (__methodname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        # We start by storing the arguments as attributes to use them later\n",
    "        # arguments\n",
    "        self.model      = model\n",
    "        self.loss_fn    = loss_fn\n",
    "        self.optimizer  = optimizer\n",
    "        self.device     = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # placeholders for later\n",
    "        self.train_loader   = None\n",
    "        self.val_loader     = None\n",
    "        self.writer         = None\n",
    "\n",
    "        # variables\n",
    "        self.train_losses   = []\n",
    "        self.val_losses     = []\n",
    "        self.total_epochs   = 0\n",
    "\n",
    "        # Creates the train_step function for our model, loss function and optimizer\n",
    "        self.train_step_fn  = self._make_train_step_fn()\n",
    "        # Creates the val_step function for our model and loss function\n",
    "        self.val_step_fn    = self._make_val_step_fn()\n",
    "\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which data loaders to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader   = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to specify a name for SummaryWriter\n",
    "        # to interface with TensorBoard\n",
    "        suffix = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')\n",
    "\n",
    "    def _make_train_step_fn(self):\n",
    "        # Builds function that performs a step in the train loop\n",
    "        def perform_train_step_fn(x, y):\n",
    "            # Set model to TRAIN mode\n",
    "            self.model.train()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "\n",
    "            # Step 3 - Computes gradients for both model's parameters and loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Step 4 - Updates parameters using gradients and the chosen optimizer\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Returns the loss\n",
    "            return loss.item()\n",
    "        \n",
    "        # Returns the function that will be called inside the train loop\n",
    "        return perform_train_step_fn\n",
    "    \n",
    "    def _make_val_step_fn(self):\n",
    "        # Builds function that performs a step in the validation loop\n",
    "        def perform_val_step_fn(x, y):\n",
    "            # Set model to EVAL mode\n",
    "            self.model.eval()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "\n",
    "            # Returns the loss and the predictions\n",
    "            return loss.item()\n",
    "        \n",
    "        # Returns the function that will be called inside the val loop\n",
    "        return perform_val_step_fn\n",
    "    \n",
    "    def _mini_batch(self, validation=False):\n",
    "        # The mini-batch method can be used with both loaders\n",
    "        # The argument 'validation' defines which loader and \n",
    "        # corresponding step function will be used\n",
    "        if validation:\n",
    "            data_loader = self.val_loader\n",
    "            step_fn     = self.val_step_fn\n",
    "        else:\n",
    "            data_loader = self.train_loader\n",
    "            step_fn     = self.train_step_fn\n",
    "\n",
    "        # Initializes an empty list to accumulate the losses\n",
    "        mini_batch_losses = []\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "\n",
    "            mini_batch_loss = step_fn(x_batch, y_batch)\n",
    "            mini_batch_losses.append(mini_batch_loss)\n",
    "        \n",
    "        loss = np.mean(mini_batch_losses)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def set_seed(self, seed=42):\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark     = False\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "\n",
    "    def train(self, n_epochs, seed=42):\n",
    "        # To ensure reproducibility of the training process\n",
    "        self.set_seed(seed)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # Keeps track of the number of epochs\n",
    "            # by updating the corresponding attribute\n",
    "            self.total_epochs += 1\n",
    "\n",
    "            # Training loop\n",
    "            train_loss = self._mini_batch(validation=False)\n",
    "            self.train_losses.append(train_loss)\n",
    "\n",
    "            # Validation loop\n",
    "            if self.val_loader is not None:\n",
    "                with torch.no_grad():\n",
    "                    val_loss = self._mini_batch(validation=True)\n",
    "                    self.val_losses.append(val_loss)\n",
    "\n",
    "            if self.writer is not None:\n",
    "                scalars = {'training': train_loss}\n",
    "                if val_loss is not None:\n",
    "                    scalars.update({'validation': val_loss})\n",
    "                # Records both losses to tensorboard for each epoch under tag \"loss\"\n",
    "                self.writer.add_scalars(\n",
    "                    main_tag='loss',\n",
    "                    tag_scalar_dict=scalars,\n",
    "                    global_step=epoch\n",
    "                )\n",
    "            \n",
    "        if self.writer is not None:\n",
    "            # Fflushes the writer\n",
    "            self.writer.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        # We start by storing the arguments as attributes to use them later\n",
    "        # arguments\n",
    "        self.model      = model\n",
    "        self.loss_fn    = loss_fn\n",
    "        self.optimizer  = optimizer\n",
    "        self.device     = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # placeholders for later\n",
    "        self.train_loader   = None\n",
    "        self.val_loader     = None\n",
    "        self.writer         = None\n",
    "\n",
    "        # variables\n",
    "        self.train_losses   = []\n",
    "        self.val_losses     = []\n",
    "        self.total_epochs   = 0\n",
    "\n",
    "        # Creates the train_step function for our model, loss function and optimizer\n",
    "        self.train_step_fn  = self._make_train_step_fn()\n",
    "        # Creates the val_step function for our model and loss function\n",
    "        self.val_step_fn    = self._make_val_step_fn()\n",
    "\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which data loaders to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader   = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to specify a name for SummaryWriter\n",
    "        # to interface with TensorBoard\n",
    "        suffix = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')\n",
    "\n",
    "    def _make_train_step_fn(self):\n",
    "        # Builds function that performs a step in the train loop\n",
    "        def perform_train_step_fn(x, y):\n",
    "            # Set model to TRAIN mode\n",
    "            self.model.train()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "\n",
    "            # Step 3 - Computes gradients for both model's parameters and loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Step 4 - Updates parameters using gradients and the chosen optimizer\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Returns the loss\n",
    "            return loss.item()\n",
    "        \n",
    "        # Returns the function that will be called inside the train loop\n",
    "        return perform_train_step_fn\n",
    "    \n",
    "    def _make_val_step_fn(self):\n",
    "        # Builds function that performs a step in the validation loop\n",
    "        def perform_val_step_fn(x, y):\n",
    "            # Set model to EVAL mode\n",
    "            self.model.eval()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "\n",
    "            # Returns the loss and the predictions\n",
    "            return loss.item()\n",
    "        \n",
    "        # Returns the function that will be called inside the val loop\n",
    "        return perform_val_step_fn\n",
    "    \n",
    "    def _mini_batch(self, validation=False):\n",
    "        # The mini-batch method can be used with both loaders\n",
    "        # The argument 'validation' defines which loader and \n",
    "        # corresponding step function will be used\n",
    "        if validation:\n",
    "            data_loader = self.val_loader\n",
    "            step_fn     = self.val_step_fn\n",
    "        else:\n",
    "            data_loader = self.train_loader\n",
    "            step_fn     = self.train_step_fn\n",
    "\n",
    "        # Initializes an empty list to accumulate the losses\n",
    "        mini_batch_losses = []\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "\n",
    "            mini_batch_loss = step_fn(x_batch, y_batch)\n",
    "            mini_batch_losses.append(mini_batch_loss)\n",
    "        \n",
    "        loss = np.mean(mini_batch_losses)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def set_seed(self, seed=42):\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark     = False\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "\n",
    "    def train(self, n_epochs, seed=42):\n",
    "        # To ensure reproducibility of the training process\n",
    "        self.set_seed(seed)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # Keeps track of the number of epochs\n",
    "            # by updating the corresponding attribute\n",
    "            self.total_epochs += 1\n",
    "\n",
    "            # Training loop\n",
    "            train_loss = self._mini_batch(validation=False)\n",
    "            self.train_losses.append(train_loss)\n",
    "\n",
    "            # Validation loop\n",
    "            if self.val_loader is not None:\n",
    "                with torch.no_grad():\n",
    "                    val_loss = self._mini_batch(validation=True)\n",
    "                    self.val_losses.append(val_loss)\n",
    "\n",
    "            if self.writer is not None:\n",
    "                scalars = {'training': train_loss}\n",
    "                if val_loss is not None:\n",
    "                    scalars.update({'validation': val_loss})\n",
    "                # Records both losses to tensorboard for each epoch under tag \"loss\"\n",
    "                self.writer.add_scalars(\n",
    "                    main_tag='loss',\n",
    "                    tag_scalar_dict=scalars,\n",
    "                    global_step=epoch\n",
    "                )\n",
    "            \n",
    "        if self.writer is not None:\n",
    "            # Fflushes the writer\n",
    "            self.writer.flush()\n",
    "\n",
    "\n",
    "    def save_checkpoint(self, filename):\n",
    "        # Builds dictionary with all elements for resuming training\n",
    "        checkpoint = {\n",
    "            'epoch': self.total_epochs,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "    def load_checkpoint(self, filename):\n",
    "        # Loads dictionary\n",
    "        checkpoint = torch.load(filename)\n",
    "\n",
    "        # Restore state for model and optimizer\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.total_epochs = checkpoint['epoch']\n",
    "        self.train_losses = checkpoint['train_losses']\n",
    "        self.val_losses   = checkpoint['val_losses']\n",
    "        self.model.train()      # Make sure model is in train mode\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Set model to EVAL mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Send input to device and computes predictions\n",
    "        x = x.to(self.device)\n",
    "        yhat = self.model(x)\n",
    "\n",
    "        # Set model back to TRAIN mode\n",
    "        self.model.train()\n",
    "        \n",
    "        # Returns predictions\n",
    "        return yhat.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../stepbystep/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '../stepbystep/v0.py'\n",
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        # We start by storing the arguments as attributes to use them later\n",
    "        # arguments\n",
    "        self.model      = model\n",
    "        self.loss_fn    = loss_fn\n",
    "        self.optimizer  = optimizer\n",
    "        self.device     = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # placeholders for later\n",
    "        self.train_loader   = None\n",
    "        self.val_loader     = None\n",
    "        self.writer         = None\n",
    "\n",
    "        # variables\n",
    "        self.train_losses   = []\n",
    "        self.val_losses     = []\n",
    "        self.total_epochs   = 0\n",
    "\n",
    "        # Creates the train_step function for our model, loss function and optimizer\n",
    "        self.train_step_fn  = self._make_train_step_fn()\n",
    "        # Creates the val_step function for our model and loss function\n",
    "        self.val_step_fn    = self._make_val_step_fn()\n",
    "\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which data loaders to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader   = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to specify a name for SummaryWriter\n",
    "        # to interface with TensorBoard\n",
    "        suffix = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')\n",
    "\n",
    "    def _make_train_step_fn(self):\n",
    "        # Builds function that performs a step in the train loop\n",
    "        def perform_train_step_fn(x, y):\n",
    "            # Set model to TRAIN mode\n",
    "            self.model.train()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "\n",
    "            # Step 3 - Computes gradients for both model's parameters and loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Step 4 - Updates parameters using gradients and the chosen optimizer\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Returns the loss\n",
    "            return loss.item()\n",
    "        \n",
    "        # Returns the function that will be called inside the train loop\n",
    "        return perform_train_step_fn\n",
    "    \n",
    "    def _make_val_step_fn(self):\n",
    "        # Builds function that performs a step in the validation loop\n",
    "        def perform_val_step_fn(x, y):\n",
    "            # Set model to EVAL mode\n",
    "            self.model.eval()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "\n",
    "            # Returns the loss and the predictions\n",
    "            return loss.item()\n",
    "        \n",
    "        # Returns the function that will be called inside the val loop\n",
    "        return perform_val_step_fn\n",
    "    \n",
    "    def _mini_batch(self, validation=False):\n",
    "        # The mini-batch method can be used with both loaders\n",
    "        # The argument 'validation' defines which loader and \n",
    "        # corresponding step function will be used\n",
    "        if validation:\n",
    "            data_loader = self.val_loader\n",
    "            step_fn     = self.val_step_fn\n",
    "        else:\n",
    "            data_loader = self.train_loader\n",
    "            step_fn     = self.train_step_fn\n",
    "\n",
    "        # Initializes an empty list to accumulate the losses\n",
    "        mini_batch_losses = []\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "\n",
    "            mini_batch_loss = step_fn(x_batch, y_batch)\n",
    "            mini_batch_losses.append(mini_batch_loss)\n",
    "        \n",
    "        loss = np.mean(mini_batch_losses)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def set_seed(self, seed=42):\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark     = False\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "\n",
    "    def train(self, n_epochs, seed=42):\n",
    "        # To ensure reproducibility of the training process\n",
    "        self.set_seed(seed)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # Keeps track of the number of epochs\n",
    "            # by updating the corresponding attribute\n",
    "            self.total_epochs += 1\n",
    "\n",
    "            # Training loop\n",
    "            train_loss = self._mini_batch(validation=False)\n",
    "            self.train_losses.append(train_loss)\n",
    "\n",
    "            # Validation loop\n",
    "            if self.val_loader is not None:\n",
    "                with torch.no_grad():\n",
    "                    val_loss = self._mini_batch(validation=True)\n",
    "                    self.val_losses.append(val_loss)\n",
    "\n",
    "            if self.writer is not None:\n",
    "                scalars = {'training': train_loss}\n",
    "                if val_loss is not None:\n",
    "                    scalars.update({'validation': val_loss})\n",
    "                # Records both losses to tensorboard for each epoch under tag \"loss\"\n",
    "                self.writer.add_scalars(\n",
    "                    main_tag='loss',\n",
    "                    tag_scalar_dict=scalars,\n",
    "                    global_step=epoch\n",
    "                )\n",
    "            \n",
    "        if self.writer is not None:\n",
    "            # Fflushes the writer\n",
    "            self.writer.flush()\n",
    "\n",
    "\n",
    "    def save_checkpoint(self, filename):\n",
    "        # Builds dictionary with all elements for resuming training\n",
    "        checkpoint = {\n",
    "            'epoch': self.total_epochs,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "    def load_checkpoint(self, filename):\n",
    "        # Loads dictionary\n",
    "        checkpoint = torch.load(filename)\n",
    "\n",
    "        # Restore state for model and optimizer\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.total_epochs = checkpoint['epoch']\n",
    "        self.train_losses = checkpoint['train_losses']\n",
    "        self.val_losses   = checkpoint['val_losses']\n",
    "        self.model.train()      # Make sure model is in train mode\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Set model to EVAL mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Send input to device and computes predictions\n",
    "        x = x.to(self.device)\n",
    "        yhat = self.model(x)\n",
    "\n",
    "        # Set model back to TRAIN mode\n",
    "        self.model.train()\n",
    "        \n",
    "        # Returns predictions\n",
    "        return yhat.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    def plot_losses(self):\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.train_losses, label='Training loss', c='b')\n",
    "        if self.val_loader is not None:\n",
    "            plt.plot(self.val_losses, label='Validation loss', c='r')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.yscale('log')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return fig\n",
    "    \n",
    "\n",
    "    def add_graph(self):\n",
    "        if self.train_loader is not None and self.writer is not None:\n",
    "            # Gets a sample input\n",
    "            x, _ = next(iter(self.train_loader))\n",
    "            x = x.to(self.device)\n",
    "\n",
    "            # Adds model to tensorboard\n",
    "            self.writer.add_graph(self.model, x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classy Pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

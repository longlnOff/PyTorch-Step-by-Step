{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060\n",
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "torch.__version__\n",
    "device = 'cuda' if torch.cuda.is_available()  else 'cpu'\n",
    "n_cudas = torch.cuda.device_count()\n",
    "for i in range(n_cudas):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1400, device='cuda:0')\n",
      "tensor([1, 2, 3], device='cuda:0')\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], device='cuda:0')\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[7, 8, 9],\n",
      "         [0, 1, 2]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(3.14, device=device)\n",
    "vector = torch.tensor([1, 2, 3], device=device)\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]], device=device)\n",
    "tensor = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [0, 1, 2]]], device=device)\n",
    "print(scalar)\n",
    "print(vector)\n",
    "print(matrix)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 3]), torch.Size([2, 2, 3]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.size(), tensor.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5, 6]], device='cuda:0')\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Use view() method to reshape the tensor\n",
    "# Beware: the view() method only returns a tensor with the dsired shape\n",
    "# that shares the same underlying data with original tensor - it DOES NOT create a new tensor!\n",
    "same_matrix = matrix.view(1, -1)\n",
    "print(same_matrix)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100,   2,   3,   4,   5,   6]], device='cuda:0')\n",
      "tensor([[100,   2,   3],\n",
      "        [  4,   5,   6]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "same_matrix[0, 0] = 100\n",
    "print(same_matrix)\n",
    "print(matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100,   2,   3,   4,   5,   6]], device='cuda:0')\n",
      "tensor([[1234,    2,    3,    4,    5,    6]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# use .clone().detach() to copy a tensor instead of view()\n",
    "other_tensor = same_matrix.clone().detach()\n",
    "other_tensor[0,0] = 1234\n",
    "print(same_matrix)\n",
    "print(other_tensor)\n",
    "# search detach() and clone() in pytorch doc for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1234,    2,    3,    4,    5,    6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if tensor in GPU, we must conver to cpu first, then convert to numpy\n",
    "print(other_tensor.device)\n",
    "other_tensor.cpu().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Tensor versus Trainable Tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normal Tensor: Doesn't require gradient computation.\n",
    "- Trainable Tensor (Parameter/weight): Requires gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3048], device='cuda:0', requires_grad=True) tensor([-1.2870], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Standard method to create Trainable Tensor\n",
    "# We must specify the requires_grad=True to track computation\n",
    "# and specify the device to be the GPU\n",
    "# this method also accelerates the computation (see 7 PyTorch Tips Github)\n",
    "torch.manual_seed(7)\n",
    "b = torch.randn(1, requires_grad=True, device=device)\n",
    "w = torch.randn(1, requires_grad=True, device=device)\n",
    "print(b, w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd is PyTorch's *automatic differentiation package* that automatically calculates derivatives, chain rule or anything like it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backward() method compute all gradients for all (requires_grad=True) tensors involved in the computation of a given variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], device=device, dtype=torch.float32)\n",
    "y_train = torch.tensor([11, 22, 33, 44, 53, 66, 77, 87, 95], device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autograd in action\n",
    "# Step 1 - Computes our model's predicted output - forward pass\n",
    "yhat = b + w * x_train\n",
    "\n",
    "# Step 2 - Computes the loss\n",
    "error = (yhat - y_train)\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "# Step 3 - Computes the gradients for every parameter with requires_grad=True\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True True\n",
      "False False\n"
     ]
    }
   ],
   "source": [
    "print(b.requires_grad, w.requires_grad, loss.requires_grad, error.requires_grad)\n",
    "print(x_train.requires_grad, y_train.requires_grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use grad attribute to check actual values of the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58158/1389219517.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
      "  b.grad, w.grad, loss.grad, error.grad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-121.9243], device='cuda:0'),\n",
       " tensor([-769.2258], device='cuda:0'),\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad, w.grad, loss.grad, error.grad\n",
    "# grad value of loss and error is None because they are not leaf node"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NOTE: PyTorch default is accumulating gradients. We need to clear them out before each instance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.], device='cuda:0'), tensor([0.], device='cuda:0'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every time we use the gradients to update the parameters, we need to zero the gradients afterwards.\n",
    "b.grad.zero_(), w.grad.zero_()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

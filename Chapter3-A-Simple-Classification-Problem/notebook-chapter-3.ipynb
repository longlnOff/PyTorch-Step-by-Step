{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spoilers\n",
    "- build a model for binary classification\n",
    "- understanding the concept of logits and how it is related to probabilities\n",
    "- use binary cross entropy as a loss function to train model\n",
    "- use the loss function to handle imbalanced dataset\n",
    "- understanding the concepts of decision boundary and separability\n",
    "- learn how the choice of a classification threshold impacts evaluation metrics\n",
    "- build ROC and precision-recall curves to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "path_src = str(Path().resolve().parents[0])\n",
    "sys.path.append(path_src)\n",
    "from stepbystep.v0 import StepByStep\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Classification Problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In classification problem, we're trying to predict which class a data point belongs to."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=100, noise=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "\n",
    "x_train = sc.transform(x_train)\n",
    "x_val   = sc.transform(x_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Remember, only use the training set to fit the StandardScaler and then use it transform() method to apply the pre-processing step to all datasets. \n",
    "- REMEMBER: You should never fit() the test set, ONLY Train set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train.reshape(-1,1)).float()\n",
    "\n",
    "x_val_tensor = torch.from_numpy(x_val).float()\n",
    "y_val_tensor = torch.from_numpy(y_val.reshape(-1,1)).float()\n",
    "\n",
    "# Builds dataset contain All data points\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "\n",
    "# Builds data loader contain mini-batches\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[-0.5773, -0.0292]])),\n",
       "             ('0.bias', tensor([0.4392]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(13)\n",
    "model1 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2,1),\n",
    "    torch.nn.Sigmoid())\n",
    "model1.state_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BCELoss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FULLCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Preparation\n",
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train.reshape(-1,1)).float()\n",
    "\n",
    "x_val_tensor = torch.from_numpy(x_val).float()\n",
    "y_val_tensor = torch.from_numpy(y_val.reshape(-1,1)).float()\n",
    "\n",
    "# Builds dataset contain All data points\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "\n",
    "# Builds data loader contain mini-batches\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Model Configuration\n",
    "# learning rate\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Build the model\n",
    "torch.manual_seed(42)\n",
    "model_class = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer_class = torch.optim.SGD(model_class.parameters(), lr=learning_rate)\n",
    "\n",
    "# Loss function\n",
    "loss_function_class = torch.nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Training Model\n",
    "n_epochs = 100\n",
    "sbs = StepByStep(\n",
    "    model=model_class,\n",
    "    loss_fn=loss_function_class,\n",
    "    optimizer=optimizer_class,\n",
    ")\n",
    "\n",
    "sbs.set_loaders(train_loader, val_loader)\n",
    "sbs.train(n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  4],\n",
       "       [10,  1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_val = sbs.predict(x_val_tensor)\n",
    "confusion_matrix(y_val, logits_val >= 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
